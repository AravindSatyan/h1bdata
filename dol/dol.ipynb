{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb='BINFOpJQiWmp1JIa'\n",
    "mongodb1='25w9gXhCYvSdNYho'\n",
    "\n",
    "import re\n",
    "import glob\n",
    "lst=glob.glob('**/*')\n",
    "lst\n",
    "for i in lst:\n",
    "    a=re.search('FY\\d*\\_?\\w+',''.join(i))\n",
    "    a=a.group(0)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is successfully dumped into PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, datetime as dt, glob\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "\n",
    "def main_dataset():\n",
    "        \n",
    "        a=glob.glob('**/*')\n",
    "        df=pd.DataFrame()\n",
    "        for i in range(len(a)):\n",
    "                k=a[i]\n",
    "                df_start=dt.datetime.now()\n",
    "                df=pd.read_excel(k)\n",
    "                df['link']=f'{k}'\n",
    "                u = df.select_dtypes(include=['datetime'])\n",
    "                df[u.columns] = u.fillna('None')\n",
    "                df=df.fillna('None')\n",
    "                df_end=dt.datetime.now()\n",
    "                print(f'df, done {k} {df.shape} time is: {df_end-df_start}')\n",
    "                sql_start=dt.datetime.now()\n",
    "                df.to_sql(f'table_is_{i}', engine, if_exists='replace', index=False)\n",
    "                sql_end=dt.datetime.now()\n",
    "                print(f'table_is_{i} also done and the time it took is {sql_end-sql_start}')\n",
    "\n",
    "        return df\n",
    "\n",
    "# df=main_dataset()\n",
    "print(\"DataFrame is successfully dumped into PostgreSQL database.\")\n",
    "# df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table is 0, the shape is: (120306, 97)\n",
      "time to query: 0:00:07.455208\n",
      "time to json: 0:00:03.032074\n"
     ]
    }
   ],
   "source": [
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "def get_full_data(engine):\n",
    "\n",
    "    with open (r'dol-h1b-data-final.json', mode='a', encoding = 'utf-8-sig') as file:\n",
    "        for i in range(20):\n",
    "            starttime_sql_query=dt.datetime.now()\n",
    "            query= f'select * from table_is_{i}'\n",
    "            temp_df = pd.read_sql(query, engine)\n",
    "            endtime_sql_query = dt.datetime.now()\n",
    "            temp_df.to_json(file, orient='records')\n",
    "            end_time_df_json= dt.datetime.now()\n",
    "            print(f'table is {i}, the shape is: {temp_df.shape}')\n",
    "            print(f'time to query: {endtime_sql_query-starttime_sql_query}')\n",
    "            print(f'time to json: {end_time_df_json - endtime_sql_query}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data has been inserted into the 'users' collection.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import datetime as dt\n",
    "\n",
    "def load_sample_data(df):\n",
    "    mono_start=dt.datetime.now()\n",
    "    atlas_connection_string = \"mongodb+srv://aravindbedean:25w9gXhCYvSdNYho@cluster0.cbcz4vn.mongodb.net/?retryWrites=true&w=majority\"\n",
    "    client = MongoClient(atlas_connection_string)\n",
    "    db = client['sample_db']\n",
    "    collection = db['users']\n",
    "    collection.insert_many(df)\n",
    "    mongo_end=dt.datetime.now()\n",
    "    print(f'time to load to mongo is: {mongo_end-mono_start}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json, datetime as dt\n",
    "# query= 'select * from table_is_0'\n",
    "# temp_df = pd.read_sql(query, engine)\n",
    "\n",
    "# with open (r'/Users/hariaravi/PycharmProjects/finalGHfolder/Data_Engineering/Projects/h1b/dol-h1b-data-final.json', mode='a', encoding = 'utf-8-sig') as file:\n",
    "#     for i in range(20):\n",
    "#         # starttime_sql_query=dt.datetime.now()\n",
    "#         query= f'select * from table_is_{i}'\n",
    "#         temp_df = pd.read_sql(query, engine)\n",
    "#         # endtime_sql_query = dt.datetime.now()\n",
    "#         temp_df.to_json(file, lines=True, orient='records')\n",
    "#         # end_time_df_json= dt.datetime.now()\n",
    "#         # print(f'table is {i}, the shape is: {temp_df.shape}')\n",
    "#         # print(f'time to query: {endtime_sql_query-starttime_sql_query}')\n",
    "#         # print(f'time to json: {end_time_df_json - endtime_sql_query}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##libraries\n",
    "\n",
    "\n",
    "import pandas as pd, datetime as dt, glob, decimal, ijson, time as t, os, json, pyarrow\n",
    "from pytz import timezone\n",
    "from bson.decimal128 import Decimal128\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, datetime as dt, glob, decimal, ijson, time as t, os, json, pyarrow\n",
    "from pytz import timezone\n",
    "from bson.decimal128 import Decimal128\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "def date_and_time():\n",
    "    format = \"%Y-%m-%d_%H-%M\"\n",
    "    now_utc = dt.datetime.now(timezone('EST'))\n",
    "    return now_utc.strftime(format)\n",
    "\n",
    "def get_full_data(engine,datetime):\n",
    "    data_file = f'final/dol-h1b-data-final-{datetime}.json'\n",
    "    with open (r'{}'.format(data_file), mode='a', encoding = 'utf-8-sig') as file:\n",
    "        for i in range(2):\n",
    "            starttime_sql_query=dt.datetime.now()\n",
    "            query= f'select * from table_is_{i}'\n",
    "            temp_df = pd.read_sql(query, engine)\n",
    "            endtime_sql_query = dt.datetime.now()\n",
    "            temp_df.to_json(file, orient='records')\n",
    "            end_time_df_json= dt.datetime.now()\n",
    "            print(f'table is {i}, the shape is: {temp_df.shape}')\n",
    "            print(f'time to query: {endtime_sql_query-starttime_sql_query}')\n",
    "            print(f'time to json: {end_time_df_json - endtime_sql_query}')\n",
    "        file_name = file.name\n",
    "        abs_path=os.path.abspath(file_name)\n",
    "        return abs_path     \n",
    "\n",
    "def convert_decimal128(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            obj[k] = convert_decimal128(v)\n",
    "    elif isinstance(obj, list):\n",
    "        obj = [convert_decimal128(v) for v in obj]\n",
    "    elif isinstance(obj, decimal.Decimal):\n",
    "        return Decimal128(str(obj))\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "def load_data(df):\n",
    "    with open (r'{}'.format(df),mode = 'r', encoding = 'utf-8-sig') as file:\n",
    "        array_items = ijson.items(file, 'item')\n",
    "        temp_list=[]\n",
    "        count=0\n",
    "        for i in array_items:\n",
    "            atlas_connection_string = \"mongodb+srv://aravindbedean:25w9gXhCYvSdNYho@cluster0.cbcz4vn.mongodb.net/?retryWrites=true&w=majority\"\n",
    "            client = MongoClient(atlas_connection_string)\n",
    "            db = client['dol-h1b']\n",
    "            collection = db['datadump']\n",
    "            i=convert_decimal128(i)\n",
    "            collection.insert_one(i)\n",
    "        # temp_list.clear()\n",
    "        # print(len(temp_list))\n",
    " \n",
    "                \n",
    "def operation():\n",
    "    pg_db = pg_db_connection()\n",
    "    temp_variable=get_full_data(pg_db, date_and_time())\n",
    "    # final_end = load_data(temp_variable)\n",
    "    # final_end = load_data(r'/Users/hariaravi/PycharmProjects/dol-h1b/h1bdata/dol/final/dol-h1b-data-final-2024-02-24_16-57.json')\n",
    "    \n",
    "    print('All functions done')\n",
    "\n",
    "        \n",
    "# operation()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-25 20:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Your timestamp in milliseconds\n",
    "timestamp_ms = \"1632614400000\"\n",
    "\n",
    "# Convert the string to an integer and then to seconds\n",
    "timestamp_s = int(timestamp_ms) / 1000.0\n",
    "\n",
    "# Convert the timestamp to a datetime object\n",
    "dt = datetime.fromtimestamp(timestamp_s)\n",
    "\n",
    "print(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "with open (r'/Users/hariaravi/PycharmProjects/dol-h1b/h1bdata/dol/final/dol-h1b-data-final-2024-02-24_16-57.json', mode='r',encoding='utf-8-sig') as file:\n",
    "    a_file=ijson.items(file,\"item\")\n",
    "    temp_list=[]\n",
    "    for i,j in enumerate(a_file):\n",
    "        if len(temp_list) == 10: #1000000):\n",
    "            break\n",
    "        elif len(temp_list) < 10: #1000000):\n",
    "            temp_list.append(j)\n",
    "\n",
    "    print(len(temp_list))\n",
    "    mini_df=pd.DataFrame(temp_list)\n",
    "    # print(mini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_is_0 has the following shape (28, 98)\n",
      "table_is_1 has the following shape (61, 54)\n",
      "table_is_2 has the following shape (39, 98)\n",
      "table_is_3 has the following shape (31, 54)\n",
      "table_is_4 has the following shape (25, 98)\n",
      "table_is_5 has the following shape (22, 42)\n",
      "table_is_6 has the following shape (20, 98)\n",
      "table_is_7 has the following shape (112, 98)\n",
      "table_is_8 has the following shape (31, 98)\n",
      "table_is_9 has the following shape (35, 98)\n",
      "table_is_10 has the following shape (42, 98)\n",
      "table_is_11 has the following shape (43, 98)\n",
      "table_is_12 has the following shape (67, 98)\n",
      "table_is_13 has the following shape (41, 98)\n",
      "table_is_14 has the following shape (63, 98)\n",
      "table_is_15 has the following shape (61, 262)\n",
      "table_is_16 has the following shape (32, 98)\n",
      "table_is_17 has the following shape (35, 98)\n",
      "table_is_18 has the following shape (33, 98)\n",
      "table_is_19 has the following shape (28, 98)\n",
      "Excel sheet is ready\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "cit_y='cupertino'\n",
    "rol_e='data'\n",
    "for i in range(20):\n",
    "    engine = pg_db_connection()\n",
    "    temp_df = pd.read_sql(('select * from table_is_'+str(i)+' where  \\\"EMPLOYER_CITY\\\" ilike %(city)s and \\\"JOB_TITLE\\\" ilike %(role)s')\n",
    "                          , engine, params={\"city\": f'%{cit_y}%', \"role\":f'%{rol_e}%'})\n",
    "    temp_df['table'] = f'table_is_{i}'\n",
    "    df=pd.concat([df,temp_df])\n",
    "    print(f'table_is_{i} has the following shape {temp_df.shape}')\n",
    "\n",
    "df.to_excel(f'{cit_y}_{rol_e}.xlsx')\n",
    "print('Excel sheet is ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apple Inc.', 'SEAGATE US LLC', 'APPLE INC.',\n",
       "       'STEP AHEAD SOLUTIONS INC', 'MIST SYSTEMS, INC.',\n",
       "       'EXILANT TECHNOLOGIES PRIVATE LIMITED', 'LINO CORP',\n",
       "       'GAMELORE,INC.', 'PYRAMES INC.', 'MIRAPATH, INC.',\n",
       "       'SUGARCRM, INC.', 'INDX TECHNOLOGY, INC.',\n",
       "       'AC Wellness Network LLC', 'A2Z DEVELOPMENT CENTER, INC.',\n",
       "       'BOARDWALKTECH, INC.', 'PyrAmes, Inc.', 'APPLE, INC.',\n",
       "       'Apple Inc. ', 'Armorblox, Inc.', 'Mobileum, Inc.',\n",
       "       'Seagate US LLC', 'Boardwalktech, Inc. ', 'ROADSTAR.AI LLC',\n",
       "       'PLUSAI, INC.', 'JOYMOBI TECHNOLOGY INC.',\n",
       "       'COLLTECH CORPORATION, INC.', 'VINGS TECHNOLOGIES LIMITED',\n",
       "       'Boardwalktech, Inc.', 'PharmaAI', 'INDIUM SOFTWARE, INC.',\n",
       "       'Tosha Home Inc.', 'MobiSocial, Inc. '], dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EMPLOYER_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
