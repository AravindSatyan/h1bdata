{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb='BINFOpJQiWmp1JIa'\n",
    "mongodb1='25w9gXhCYvSdNYho'\n",
    "\n",
    "import re\n",
    "import glob\n",
    "lst=glob.glob('**/*')\n",
    "lst\n",
    "for i in lst:\n",
    "    a=re.search('FY\\d*\\_?\\w+',''.join(i))\n",
    "    a=a.group(0)\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is successfully dumped into PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, datetime as dt, glob\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "\n",
    "def main_dataset():\n",
    "        \n",
    "        a=glob.glob('**/*')\n",
    "        df=pd.DataFrame()\n",
    "        for i in range(len(a)):\n",
    "                k=a[i]\n",
    "                df_start=dt.datetime.now()\n",
    "                df=pd.read_excel(k)\n",
    "                df['link']=f'{k}'\n",
    "                u = df.select_dtypes(include=['datetime'])\n",
    "                df[u.columns] = u.fillna('None')\n",
    "                df=df.fillna('None')\n",
    "                df_end=dt.datetime.now()\n",
    "                print(f'df, done {k} {df.shape} time is: {df_end-df_start}')\n",
    "                sql_start=dt.datetime.now()\n",
    "                df.to_sql(f'table_is_{i}', engine, if_exists='replace', index=False)\n",
    "                sql_end=dt.datetime.now()\n",
    "                print(f'table_is_{i} also done and the time it took is {sql_end-sql_start}')\n",
    "\n",
    "        return df\n",
    "\n",
    "# df=main_dataset()\n",
    "print(\"DataFrame is successfully dumped into PostgreSQL database.\")\n",
    "# df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table is 0, the shape is: (120306, 97)\n",
      "time to query: 0:00:07.455208\n",
      "time to json: 0:00:03.032074\n"
     ]
    }
   ],
   "source": [
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "def get_full_data(engine):\n",
    "\n",
    "    with open (r'dol-h1b-data-final.json', mode='a', encoding = 'utf-8-sig') as file:\n",
    "        for i in range(20):\n",
    "            starttime_sql_query=dt.datetime.now()\n",
    "            query= f'select * from table_is_{i}'\n",
    "            temp_df = pd.read_sql(query, engine)\n",
    "            endtime_sql_query = dt.datetime.now()\n",
    "            temp_df.to_json(file, orient='records')\n",
    "            end_time_df_json= dt.datetime.now()\n",
    "            print(f'table is {i}, the shape is: {temp_df.shape}')\n",
    "            print(f'time to query: {endtime_sql_query-starttime_sql_query}')\n",
    "            print(f'time to json: {end_time_df_json - endtime_sql_query}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data has been inserted into the 'users' collection.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import datetime as dt\n",
    "\n",
    "def load_sample_data(df):\n",
    "    mono_start=dt.datetime.now()\n",
    "    atlas_connection_string = \"mongodb+srv://aravindbedean:25w9gXhCYvSdNYho@cluster0.cbcz4vn.mongodb.net/?retryWrites=true&w=majority\"\n",
    "    client = MongoClient(atlas_connection_string)\n",
    "    db = client['sample_db']\n",
    "    collection = db['users']\n",
    "    collection.insert_many(df)\n",
    "    mongo_end=dt.datetime.now()\n",
    "    print(f'time to load to mongo is: {mongo_end-mono_start}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json, datetime as dt\n",
    "# query= 'select * from table_is_0'\n",
    "# temp_df = pd.read_sql(query, engine)\n",
    "\n",
    "# with open (r'/Users/hariaravi/PycharmProjects/finalGHfolder/Data_Engineering/Projects/h1b/dol-h1b-data-final.json', mode='a', encoding = 'utf-8-sig') as file:\n",
    "#     for i in range(20):\n",
    "#         # starttime_sql_query=dt.datetime.now()\n",
    "#         query= f'select * from table_is_{i}'\n",
    "#         temp_df = pd.read_sql(query, engine)\n",
    "#         # endtime_sql_query = dt.datetime.now()\n",
    "#         temp_df.to_json(file, lines=True, orient='records')\n",
    "#         # end_time_df_json= dt.datetime.now()\n",
    "#         # print(f'table is {i}, the shape is: {temp_df.shape}')\n",
    "#         # print(f'time to query: {endtime_sql_query-starttime_sql_query}')\n",
    "#         # print(f'time to json: {end_time_df_json - endtime_sql_query}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##libraries\n",
    "\n",
    "\n",
    "import pandas as pd, datetime as dt, glob, decimal, ijson, time as t, os, json, pyarrow\n",
    "from pytz import timezone\n",
    "from bson.decimal128 import Decimal128\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, datetime as dt, glob, decimal, ijson, time as t, os, json, pyarrow\n",
    "from pytz import timezone\n",
    "from bson.decimal128 import Decimal128\n",
    "from sqlalchemy import create_engine\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "def date_and_time():\n",
    "    format = \"%Y-%m-%d_%H-%M\"\n",
    "    now_utc = dt.datetime.now(timezone('EST'))\n",
    "    return now_utc.strftime(format)\n",
    "\n",
    "def get_full_data(engine,datetime):\n",
    "    data_file = f'final/dol-h1b-data-final-{datetime}.json'\n",
    "    with open (r'{}'.format(data_file), mode='a', encoding = 'utf-8-sig') as file:\n",
    "        for i in range(2):\n",
    "            starttime_sql_query=dt.datetime.now()\n",
    "            query= f'select * from table_is_{i}'\n",
    "            temp_df = pd.read_sql(query, engine)\n",
    "            endtime_sql_query = dt.datetime.now()\n",
    "            temp_df.to_json(file, orient='records')\n",
    "            end_time_df_json= dt.datetime.now()\n",
    "            print(f'table is {i}, the shape is: {temp_df.shape}')\n",
    "            print(f'time to query: {endtime_sql_query-starttime_sql_query}')\n",
    "            print(f'time to json: {end_time_df_json - endtime_sql_query}')\n",
    "        file_name = file.name\n",
    "        abs_path=os.path.abspath(file_name)\n",
    "        return abs_path     \n",
    "\n",
    "def convert_decimal128(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            obj[k] = convert_decimal128(v)\n",
    "    elif isinstance(obj, list):\n",
    "        obj = [convert_decimal128(v) for v in obj]\n",
    "    elif isinstance(obj, decimal.Decimal):\n",
    "        return Decimal128(str(obj))\n",
    "    return obj\n",
    "\n",
    "\n",
    "\n",
    "def load_data(df):\n",
    "    with open (r'{}'.format(df),mode = 'r', encoding = 'utf-8-sig') as file:\n",
    "        array_items = ijson.items(file, 'item')\n",
    "        temp_list=[]\n",
    "        count=0\n",
    "        for i in array_items:\n",
    "            atlas_connection_string = \"mongodb+srv://aravindbedean:25w9gXhCYvSdNYho@cluster0.cbcz4vn.mongodb.net/?retryWrites=true&w=majority\"\n",
    "            client = MongoClient(atlas_connection_string)\n",
    "            db = client['dol-h1b']\n",
    "            collection = db['datadump']\n",
    "            i=convert_decimal128(i)\n",
    "            collection.insert_one(i)\n",
    "        # temp_list.clear()\n",
    "        # print(len(temp_list))\n",
    " \n",
    "                \n",
    "def operation():\n",
    "    pg_db = pg_db_connection()\n",
    "    temp_variable=get_full_data(pg_db, date_and_time())\n",
    "    # final_end = load_data(temp_variable)\n",
    "    # final_end = load_data(r'/Users/hariaravi/PycharmProjects/dol-h1b/h1bdata/dol/final/dol-h1b-data-final-2024-02-24_16-57.json')\n",
    "    \n",
    "    print('All functions done')\n",
    "\n",
    "        \n",
    "# operation()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-25 20:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Your timestamp in milliseconds\n",
    "timestamp_ms = \"1632614400000\"\n",
    "\n",
    "# Convert the string to an integer and then to seconds\n",
    "timestamp_s = int(timestamp_ms) / 1000.0\n",
    "\n",
    "# Convert the timestamp to a datetime object\n",
    "dt = datetime.fromtimestamp(timestamp_s)\n",
    "\n",
    "print(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "with open (r'/Users/hariaravi/PycharmProjects/dol-h1b/h1bdata/dol/final/dol-h1b-data-final-2024-02-24_16-57.json', mode='r',encoding='utf-8-sig') as file:\n",
    "    a_file=ijson.items(file,\"item\")\n",
    "    temp_list=[]\n",
    "    for i,j in enumerate(a_file):\n",
    "        if len(temp_list) == 10: #1000000):\n",
    "            break\n",
    "        elif len(temp_list) < 10: #1000000):\n",
    "            temp_list.append(j)\n",
    "\n",
    "    print(len(temp_list))\n",
    "    mini_df=pd.DataFrame(temp_list)\n",
    "    # print(mini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pg_db_connection():\n",
    "        db_username = 'postgres'\n",
    "        db_password = 'your_password'\n",
    "        db_host = 'localhost'\n",
    "        db_port = '5432'\n",
    "        db_name = 'hariaravi'\n",
    "        # SQLAlchemy engine for PostgreSQL\n",
    "        engine = create_engine(f'postgresql+psycopg2://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "        return engine\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "for i in range(20):\n",
    "    engine = pg_db_connection()\n",
    "    query = f'select * from table_is_{i} limit 5'\n",
    "    temp_df = pd.read_sql(query, engine)\n",
    "    temp_df['table'] = f'table_is_{i}'\n",
    "    df=pd.concat([df,temp_df])\n",
    "\n",
    "df.to_excel('sheet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CASE_NUMBER', 'CASE_STATUS', 'RECEIVED_DATE', 'DECISION_DATE',\n",
       "       'ORIGINAL_CERT_DATE', 'VISA_CLASS', 'JOB_TITLE', 'SOC_CODE',\n",
       "       'SOC_TITLE', 'FULL_TIME_POSITION',\n",
       "       ...\n",
       "       'PREVAILING_WAGE_10', 'PW_UNIT_OF_PAY_10', 'PW_TRACKING_NUMBER_10',\n",
       "       'PW_WAGE_LEVEL_10', 'PW_OES_YEAR_10', 'PW_OTHER_SOURCE_10',\n",
       "       'PW_NON-OES_YEAR_10', 'PW_SURVEY_PUBLISHER_10', 'PW_SURVEY_NAME_10',\n",
       "       'MASTERS_EXEMPTION'],\n",
       "      dtype='object', length=332)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set={}\n",
    "for i in df.columns:\n",
    "    temp_set[i]=[]\n",
    "    temp_set[i]= df[f'{i}'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=sorted(temp_set.items(),key = lambda x: x[1]==100, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc[0][1]==100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "for i in abc:\n",
    "    if i[1]==100:\n",
    "        res.append(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CASE_NUMBER',\n",
       " 'CASE_STATUS',\n",
       " 'DECISION_DATE',\n",
       " 'ORIGINAL_CERT_DATE',\n",
       " 'VISA_CLASS',\n",
       " 'JOB_TITLE',\n",
       " 'SOC_CODE',\n",
       " 'FULL_TIME_POSITION',\n",
       " 'EMPLOYER_NAME',\n",
       " 'EMPLOYER_CITY',\n",
       " 'EMPLOYER_STATE',\n",
       " 'EMPLOYER_POSTAL_CODE',\n",
       " 'EMPLOYER_COUNTRY',\n",
       " 'EMPLOYER_PROVINCE',\n",
       " 'EMPLOYER_PHONE',\n",
       " 'EMPLOYER_PHONE_EXT',\n",
       " 'AGENT_ATTORNEY_CITY',\n",
       " 'AGENT_ATTORNEY_STATE',\n",
       " 'WILLFUL_VIOLATOR',\n",
       " 'link',\n",
       " 'table']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "l= []\n",
    "for i in res:\n",
    "    if i !='table':\n",
    "        l.append(f'case when \"{i}\" is not null then \"{i}\" else null end as \"{i}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'case when \"CASE_NUMBER\" is not null then \"CASE_NUMBER\" else null end as \"CASE_NUMBER\",case when \"CASE_STATUS\" is not null then \"CASE_STATUS\" else null end as \"CASE_STATUS\",case when \"DECISION_DATE\" is not null then \"DECISION_DATE\" else null end as \"DECISION_DATE\",case when \"ORIGINAL_CERT_DATE\" is not null then \"ORIGINAL_CERT_DATE\" else null end as \"ORIGINAL_CERT_DATE\",case when \"VISA_CLASS\" is not null then \"VISA_CLASS\" else null end as \"VISA_CLASS\",case when \"JOB_TITLE\" is not null then \"JOB_TITLE\" else null end as \"JOB_TITLE\",case when \"SOC_CODE\" is not null then \"SOC_CODE\" else null end as \"SOC_CODE\",case when \"FULL_TIME_POSITION\" is not null then \"FULL_TIME_POSITION\" else null end as \"FULL_TIME_POSITION\",case when \"EMPLOYER_NAME\" is not null then \"EMPLOYER_NAME\" else null end as \"EMPLOYER_NAME\",case when \"EMPLOYER_CITY\" is not null then \"EMPLOYER_CITY\" else null end as \"EMPLOYER_CITY\",case when \"EMPLOYER_STATE\" is not null then \"EMPLOYER_STATE\" else null end as \"EMPLOYER_STATE\",case when \"EMPLOYER_POSTAL_CODE\" is not null then \"EMPLOYER_POSTAL_CODE\" else null end as \"EMPLOYER_POSTAL_CODE\",case when \"EMPLOYER_COUNTRY\" is not null then \"EMPLOYER_COUNTRY\" else null end as \"EMPLOYER_COUNTRY\",case when \"EMPLOYER_PROVINCE\" is not null then \"EMPLOYER_PROVINCE\" else null end as \"EMPLOYER_PROVINCE\",case when \"EMPLOYER_PHONE\" is not null then \"EMPLOYER_PHONE\" else null end as \"EMPLOYER_PHONE\",case when \"EMPLOYER_PHONE_EXT\" is not null then \"EMPLOYER_PHONE_EXT\" else null end as \"EMPLOYER_PHONE_EXT\",case when \"AGENT_ATTORNEY_CITY\" is not null then \"AGENT_ATTORNEY_CITY\" else null end as \"AGENT_ATTORNEY_CITY\",case when \"AGENT_ATTORNEY_STATE\" is not null then \"AGENT_ATTORNEY_STATE\" else null end as \"AGENT_ATTORNEY_STATE\",case when \"WILLFUL_VIOLATOR\" is not null then \"WILLFUL_VIOLATOR\" else null end as \"WILLFUL_VIOLATOR\",case when \"link\" is not null then \"link\" else null end as \"link\"'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case when \"CASE_NUMBER\" is not null then \"CASE_NUMBER\" else null end as \"CASE_NUMBER\",case when \"CASE_STATUS\" is not null then \"CASE_STATUS\" else null end as \"CASE_STATUS\",case when \"DECISION_DATE\" is not null then \"DECISION_DATE\" else null end as \"DECISION_DATE\",case when \"ORIGINAL_CERT_DATE\" is not null then \"ORIGINAL_CERT_DATE\" else null end as \"ORIGINAL_CERT_DATE\",case when \"VISA_CLASS\" is not null then \"VISA_CLASS\" else null end as \"VISA_CLASS\",case when \"JOB_TITLE\" is not null then \"JOB_TITLE\" else null end as \"JOB_TITLE\",case when \"SOC_CODE\" is not null then \"SOC_CODE\" else null end as \"SOC_CODE\",case when \"FULL_TIME_POSITION\" is not null then \"FULL_TIME_POSITION\" else null end as \"FULL_TIME_POSITION\",case when \"EMPLOYER_NAME\" is not null then \"EMPLOYER_NAME\" else null end as \"EMPLOYER_NAME\",case when \"EMPLOYER_CITY\" is not null then \"EMPLOYER_CITY\" else null end as \"EMPLOYER_CITY\",case when \"EMPLOYER_STATE\" is not null then \"EMPLOYER_STATE\" else null end as \"EMPLOYER_STATE\",case when \"EMPLOYER_POSTAL_CODE\" is not null then \"EMPLOYER_POSTAL_CODE\" else null end as \"EMPLOYER_POSTAL_CODE\",case when \"EMPLOYER_COUNTRY\" is not null then \"EMPLOYER_COUNTRY\" else null end as \"EMPLOYER_COUNTRY\",case when \"EMPLOYER_PROVINCE\" is not null then \"EMPLOYER_PROVINCE\" else null end as \"EMPLOYER_PROVINCE\",case when \"EMPLOYER_PHONE\" is not null then \"EMPLOYER_PHONE\" else null end as \"EMPLOYER_PHONE\",case when \"EMPLOYER_PHONE_EXT\" is not null then \"EMPLOYER_PHONE_EXT\" else null end as \"EMPLOYER_PHONE_EXT\",case when \"AGENT_ATTORNEY_CITY\" is not null then \"AGENT_ATTORNEY_CITY\" else null end as \"AGENT_ATTORNEY_CITY\",case when \"AGENT_ATTORNEY_STATE\" is not null then \"AGENT_ATTORNEY_STATE\" else null end as \"AGENT_ATTORNEY_STATE\",case when \"WILLFUL_VIOLATOR\" is not null then \"WILLFUL_VIOLATOR\" else null end as \"WILLFUL_VIOLATOR\",case when \"link\" is not null then \"link\" else null end as \"link\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
